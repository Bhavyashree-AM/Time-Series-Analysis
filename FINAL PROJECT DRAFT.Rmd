---
title: "Time Series Analysis & Forecasts on Seasonal and Non-Seasonal Datasets"
subtitle: "Department of Mathematical Sciences, Stevens Institute of Technology, Hoboken,NJ"
output: html_document
---

**Author: Bhavya Shree Arcot Murugeshan**

**Project Supervisor: Dr. Hadi Safari Katesari**

**ABSTRACT**
*This project aims to apply the Box-Jenkins method to analyze time series data and forecast future values using ARIMA and GARCH models. The study will use two datasets: a seasonal dataset of sunset timings and a non-seasonal dataset of Capital Bikeshare system. The Box-Jenkins approach involves identifying and estimating the parameters of an appropriate ARIMA model for the data, which will be achieved by using techniques such as autocorrelation and partial autocorrelation analysis. The GARCH model will then be applied to capture the volatility of the residuals of the ARIMA model. The resulting models will be used to forecast future values for the two datasets. The project will provide insights into the effectiveness of the Box-Jenkins method and the ARIMA and GARCH models for time series analysis and forecasting, particularly for seasonal and non-seasonal data.*

**MOTIVATION AND INTRODUCTION OF THE PROBLEM**
In this project, we will analyze two datasets, one non-seasonal and the other seasonal, to showcase the effectiveness of the Box-Jenkins method, ARIMA, and GARCH models for time series analysis and forecasting.

The non-seasonal dataset used in this project contains hourly and daily rental bike counts between 2011 and 2012 in the Capital Bikeshare system, along with corresponding weather and seasonal information. This dataset provides a valuable opportunity to analyze the demand patterns and the impact of external factors on the bike rental system's usage. The forecast derived from this dataset can assist in better planning for the bike-sharing system's efficiency and sustainability.

The seasonal dataset used in this project contains monthly average sunset timings from April 2004 to April 2023. The dataset provides a valuable opportunity to analyze the patterns and trends in sunset timings and forecast the future values accurately. This information can have significant implications in various fields, such as agriculture, transportation, and tourism, as discussed earlier.

By analyzing these two datasets, we aim to demonstrate the effectiveness of the Box-Jenkins method, ARIMA, and GARCH models for analyzing and forecasting time series data and gaining insights into the challenges and opportunities in analyzing seasonal and non-seasonal data. The project's findings can provide valuable insights to researchers, practitioners, and policymakers, helping them to make informed decisions based on time series data.

**METHODOLOGY**
The methodology for time series analysis using the Box-Jenkins method involves several steps.

*Step 1:* Stationary Check
Before fitting the time series dataset to a model, it needs to be checked for stationarity. The Dicker-Fuller test can be used in R to check for stationarity based on the p-value. If the p-value is greater than 0.05, then the data is considered non-stationary. Techniques like differencing, detrending, or transformation need to be applied in such cases, and the test should be re-run. The number of times differentiation is done until the desired p-value is obtained forms the d parameter in modeling. If the first difference is taken, then d=1 and so on.

*Step 2:* Model Selection
The model selection process is based on significant lines in the ACF and PACF plots above the confidence interval. The parameters p and q are determined based on these plots. If the plots are not clear, the EACF can be used to identify clearer values.

*Step 3:* Parameter Estimation
Based on various models and parameters, the best parameters for the time series model are chosen using measures like AIC, BIC, and log-likelihood.

*Step 4:* Residual Analysis
The chosen model must be verified for its correctness and accuracy using residual analysis. Various techniques are available to check the residuals, including starting with the ACF plot, and then moving to the QQ plot, histogram, and Shapiro-Wilk test. This helps to ensure that the model is a good fit for the data.

*Step 5:* Forecasting
Once we have a model with good parameter estimation and residual analysis, we can use it to make forecasts. For non-seasonal data, we can use ARIMA models and for seasonal data, we can use SARIMA models. We can also use GARCH models to model the volatility of the residuals. Finally, we can make forecasts and evaluate the accuracy of the model using metrics such as mean absolute error, mean squared error, and root mean squared error.

In summary, the methodology for this project involves checking for stationarity, selecting an appropriate model, estimating the model parameters, analyzing the residuals, and making forecasts. This methodology will be applied to both the seasonal and non-seasonal datasets to showcase the effectiveness of the Box-Jenkins method, ARIMA, and GARCH models for time series analysis and forecasting.

**PART I**
**Non-Seasonal Dataset**

Loading the required libraries.

```{r}
library(TSA)
library(tseries)
library(rugarch)
```

*TIME SERIES PLOT*

Loading the dataset and plotting the time series.

```{r}
setwd("C:/Users/shiva/OneDrive/Desktop/SIT Docs/TS_Project")

bike<- read.csv("bike.csv")
plot(bike$cnt, type = "l", xlab = "Day", ylab = "Count of Bikes Rented",  main = "Time Series Plot of the Bike Sharing Data")
bike_ts <- ts(bike$cnt, frequency = 365, start = c(2011,1))
```

```{r}
acf(bike$cnt, main = "ACF of Bike Sharing Data", lag.max = 100)
```

```{r}
pacf(bike$cnt, main = "PACF of Bike Sharing Data", lag.max = 100)
```

```{r}
adf.test(bike$cnt)
```

Since p > 0.05, we fail to reject null hypothesis. Therefore the series is not stationary.
We shall now take the first difference to make the series stationary.

```{r}
bike_diff <- diff(bike$cnt)
plot(bike_diff, type = "l", xlab = "Day", ylab = "Count of Bikes Rented",  main = "Time Series Plot of Differenced Series")
```

```{r}
adf.test(bike_diff)
```

Since p < 0.05, we reject null hypothesis. Therefore the series is stationary.


```{r}
acf(bike_diff, main = "ACF of Differenced Series", lag.max = 100)
```


```{r}
pacf(bike_diff,  main = "PACF of Differenced Series", lag.max = 100)
```

```{r}
eacf(bike_diff)
```


```{r}
plot(armasubsets(y=bike_diff,nar=9,nma=9,y.name='bike_diff'))

```

*MODEL FITTING*

From he above plots, the model that fits the series can be one of the following:
ARIMA(1,1,1)
ARIMA(2,1,1)

```{r}
fit_1 <- arima(bike$cnt, order = c(1,1,1))
fit_1
```

```{r}
fit_2 <- arima(bike$cnt, order = c(2,1,1))
fit_2
```


```{r}
AIC(fit_1)
BIC(fit_1)
AIC(fit_2)
BIC(fit_2)
```

We observe that the ARIMA(1,1,1) model has lower AIC and BIC. Therefore, we choose ARIMA(1,1,1) as the model with the best fit to our time series.

```{r}
coefficients(fit_1)
```

*RESIDUAL ANALYSIS*

```{r}
plot(fit_1$residuals, main = "Residual Plot for ARIMA(1,1,1) Model")
```

```{r}
residuals <- resid(fit_1)
acf(residuals, main = "ACF of Residuals for ARIMA(1,1,1) Model", lag.max=100)
```

```{r}
qqnorm(residuals, main = "Residual QQ-Plot for ARIMA(1,1,1) Model"); qqline(residuals)
```

```{r}
hist(residuals, freq = FALSE, main = "Histogram of Residuals")
```

```{r}
Box.test(residuals, lag = 10, type = "Ljung-Box")
```

Since p > 0.05, we fail to reject null hypothesis. Therefore the residuals are independent and identically distributed.

```{r}
runs(residuals)
```

Since p < 0.05, we reject null hypothesis. Therefore the series is not random.

```{r}
shapiro.test(residuals)
```

Since p < 0.05, we reject null hypothesis. Therefore the series is not Normal.

```{r}
tsdiag(fit_1, gof.lag = 100)
```

The p-values of ljung box test shows that after 30 lags, the p values are less that 0.05. This indicates that our model is not a good fit. 
Therefore, we shall consider the log difference of the time series and try to fit a model on the log differenced data.

*MODEL FITTING FOR LOG DIFFERENCE*

```{r}
bike_log <- log(bike$cnt)
plot(log(bike$cnt), type = "l", xlab = "Day", ylab = "Count of Bikes Rented",  main = "Time Series Plot of Log Transformed Series")
```

```{r}
adf.test(bike_log)
```

Since p > 0.05, we fail to reject null hypothesis. Therefore the series is not stationary.


```{r}
bike_log_diff <- diff(log(bike$cnt))
plot(diff(log(bike$cnt)), type = "l", xlab = "Day", ylab = "Count of Bikes Rented",  main = "Time Series Plot of Differenced Log Series")
```

```{r}
acf(diff(log(bike$cnt)), lag.max=100, main = "ACF of Differenced Log Series")
```

```{r}
pacf(diff(log(bike$cnt)), lag.max=100, main = "PACF of Differenced Log Series")
```

From the ACF and PACF plots, the following models can fit the log differenced time series,
ARIMA(5,1,2)
ARIMA(3,1,2)
ARIMA(3,1,1)
ARIMA(1,1,1)

```{r}
fit_3 <- arima(log(bike$cnt), order = c(5,1,2))
fit_3
```
```{r}
fit_4 <- arima(log(bike$cnt), order = c(3,1,2))
fit_4
```
```{r}
fit_5 <- arima(log(bike$cnt), order = c(3,1,1))
fit_5
```

```{r}
fit_6 <- arima(log(bike$cnt), order = c(1,1,1))
fit_6
```

Best model is ARIMA(1, 1, 1) with lowest AIC and BIC


*RESIDUAL ANALYSIS*

```{r}
acf(resid(fit_6),lag.max=150, main = "ACF of Residuals of Differenced Log Series")
```

```{r}
pacf(residuals(fit_6), lag.max=150, main = "PACF of Residuals of Differenced Log Series")
```

```{r}
tsdiag(fit_6, gof.lag = 100)
```

Therefore, the p-values of ljung box test shows that our model is a good fit. 

```{r}
qqnorm(residuals(fit_6), main = "Residual QQ-Plot for ARIMA(1,1,1) Model"); qqline(residuals(fit_6))
```

```{r}
hist(residuals(fit_6), freq = FALSE, main = "Histogram of Residuals")
```

```{r}
shapiro.test(residuals(fit_6))
```

Since p < 0.05, we reject null hypothesis. Therefore the series is not Normal.


```{r}
Box.test(residuals(fit_6), lag = 10, type = "Ljung-Box")
```

Since p > 0.05, we fail to reject null hypothesis. Therefore the residuals are independent and identically distributed.

```{r}
runs(residuals(fit_6))
```

Since p < 0.05, we reject null hypothesis. Therefore the series is not random.
Therefore, from the above residual analysis we observe that out model captures all the residuals. We conclude that ARIMA(1,1,1) is the model with best fit for our time series data.

*NON-SEASONAL FORECASTING*

Using the model that we fit, we shall now forecast the demand for bike sharing next 24 months in future.

```{r}
best_fit <- arima((bike$cnt), order = c(1,1,1))
plot(best_fit, type = 'l', n.ahead=24, ylab= 'No. of Bikes Shared', main='Bike Sharing Forecasts',pch=19, cex = 0,2)
```

```{r}
bike_ts = ts(bike$cnt, frequency = 365, start = c(2011,1))
best_fit <- arima(bike_ts, order = c(1,1,1))
plot(best_fit, n.ahead=24, n1=c(2012, 340), ylab= 'No. of Bikes Shared', main='Bike Sharing Forecasts',pch=19)
```

*ARIMA GARCH*

As we already know that the data is stationary, we can go about ﬁnding the p and q values from ACF andPACF plots 

```{r}
squared_residuals = residuals^2
plot(squared_residuals, main='Squared Residuals')
```

```{r}
acf(squared_residuals,main='ACF Squared Residuals',lag.max=100)
```

```{r}
pacf(squared_residuals,main='PACF Squared Residuals',lag.max=100)
```

As we are taking the first diﬀerence, the model we can consider is ARIMA(3,1,3) as the best model. Which is the best and q value also found from the ACF and PACF plots.

```{r}
spec <- ugarchspec(variance.model = list(model = "sGARCH",garchOrder = c(3,3),submodel = NULL,external.regressors = NULL,variance.targeting = FALSE),
mean.model = list(armaOrder = c(1,1),external.regressors = NULL))
garch2 <- ugarchfit(spec = spec, data = bike_ts, solver.control =list(trace=0))
garch2
```

```{r}
plot(garch2, which='all')
```

```{r}
forecast1 = ugarchforecast(fitORspec = garch2, n.ahead = 20)
fitted(forecast1)
```

*ARIMA GARCH FORECASTING*

```{r}
series<- c(bike_ts,rep(NA,length(fitted(forecast1))))
forecastseries<- c(rep(NA,length(bike_ts)),fitted(forecast1))
plot(series, type = "l")
lines(forecastseries, col = "green")
```


```{r}
series<- c(tail(bike_ts,100),rep(NA,length(fitted(forecast1))))
forecastseries<- c(rep(NA,100),fitted(forecast1))
plot(series, type = "l")
lines(forecastseries, col = "green")
```

Therefore, we observe that both ARIMA and ARIMA GARCH provide a similar forecast for our dataset.

**PART II**
**Seasonal Dataset**

*TIME SERIES PLOT*

Loading the dataset and plotting the seasonal time series.

```{r}
sun<- read.csv("sun.csv")
plot(sun$sunset, type = "o", xlab = "Days", ylab = "Sunset Time", main = "Time Series Plot of the Sunset Data")
```
```{r}
acf(sun$sunset, lag.max = 100, main = "ACF of the Sunset Data" )
```


```{r}
pacf(sun$sunset, lag.max = 50, main = "PACF of the Sunset Data" )
```
```{r}
adf.test(sun$sunset)
```

Since p < 0.05, we reject null hypothesis. Therefore the series is stationary.

*MODEL FITTING*

From the above ACF and PACF plots the following models could be a good fit for our seasonal data.
SARIMA(2,0,1)x(1,0,0)
SARIMA(1,0,0)x(2,0,0)
SARIMA(2,0,1)x(2,0,0)

```{r}
fit_1 <- arima(sun$sunset, order = c(2,0,1), seasonal = list(order = c(1,0,0), period = 12))
fit_1
```

```{r}
fit_2 <- arima(sun$sunset, order = c(1,0,0), seasonal = list(order = c(2,0,0), period = 12))
fit_2
```

```{r}
fit_3 <- arima(sun$sunset, order = c(2,0,1), seasonal = list(order = c(2,0,0), period = 12))
fit_3
```

```{r}
AIC(fit_1)
BIC(fit_1)
AIC(fit_2)
BIC(fit_2)
AIC(fit_3)
BIC(fit_3)
```

Best model is SARIMA(2, 0, 1)x(2, 0, 0) with lowest AIC and BIC

```{r}
coefficients(fit_3)
```

*RESIDUAL ANALYSIS*

```{r}
plot(fit_3$residuals, main = "Residual Plot for SARIMA(2, 0, 1)x(2, 0, 0) Model")
```

```{r}
residuals <- resid(fit_3)
acf(residuals, main = "ACF of Residuals for SARIMA(2, 0, 1)x(2, 0, 0) Model", lag.max = 100)
```

```{r}
tsdiag(fit_3, gof.lag = 50)
```

From the Ljung box p values, we see that the model is not a good fit since most of the p values are < 0.05.
Therefore, we try to fit the model on the log transformed data.

*MODEL FITTING ON LOG TRANSFORMED DATA*

```{r}
sun_log <- log(sun$sunset)
fit_4 <- arima(sun_log, order = c(2,1,1), seasonal = list(order = c(1,1,0), period = 12))
fit_4
```

```{r}
fit_5 <- arima(sun_log, order = c(2,1,2), seasonal = list(order = c(1,1,0), period = 12))
fit_5
```

Comparing the AIC and BIC we see that SARIMA(2,1,2)x(1,1,0) is the model with best fit.

```{r}
tsdiag(fit_5, gof.lag = 50)
```

The Ljung box p values confirms that the model is the best fit.

*RESIDUAL ANALYSIS FOR LOG TRANSFORMED TIME SERIES*

```{r}
plot(fit_5$residual, main = "Residual Plot for SARIMA(2, 1, 2)x(1, 1, 0) Model")
```

```{r}
residual <- resid(fit_5)
acf(residual, lag.max = 50)
```

```{r}
qqnorm(residual , main = "Residual Plot for SARIMA(2, 1, 2)x(1, 1, 0) Model"); qqline(residual)
```

```{r}
hist(residual, freq = FALSE, main = "Histogram of Residuals")
```


```{r}
shapiro.test(residual)
```

Since p < 0.05, we reject null hypothesis. Therefore the series is not Normal.

```{r}
Box.test(residual, lag = 10, type = "Ljung-Box")
```

Since p > 0.05, we fail to reject null hypothesis. Therefore the residuals are independent and identically distributed.

```{r}
runs(residual)
```

Since p < 0.05, we reject null hypothesis. Therefore the series is not random.
Therefore, from the above analysis we see that the model we fit captures the residuals.

*SEASONAL FORECASTING*

```{r}
fit <- arima(sun$sunset, order = c(2,1,2), seasonal = list(order = c(1,1,0), period = 12))
plot(fit, type = 'o', n.ahead=24, ylab= 'Sunset Time', main='Sunset Forecasts',pch=19, cex = 1,2)
```

**CONCLUSION**
In this project, we have used the Box-Jenkins methodology for time series analysis and forecasting. We have applied this methodology to two different datasets: one is a non-seasonal dataset - the Capital Bike sharing dataset, and the other is a seasonal dataset - monthly average sunset timings.

For the non-seasonal dataset, we started by performing a stationary check using the Dicker-Fuller test. We found that the data was non-stationary, so we applied differencing until we achieved stationarity. We then used the ACF and PACF plots to select the best model. Based on the significant lines in the plots, we chose to fit an ARIMA(1,1,1) model. We then performed parameter estimation using AIC, BIC, and log-likelihood methods and selected the best parameters for the model. We then conducted residual analysis using various techniques such as ACF plots, QQ plots, histograms, and the Shapiro-Wilk test to verify the accuracy and correctness of the model. Finally, we fit a GARCH(3,1,3) model to the dataset.

For the seasonal dataset, we performed a stationary check using the Dicker-Fuller test and found that the data was non-stationary. We applied differencing and seasonal differencing to achieve stationarity. We then used the ACF and PACF plots to select the best model. Based on the significant lines in the plots, we chose to fit a SARIMA(2,1,2)x(1,1,0) model. We then performed parameter estimation using AIC, BIC, and log-likelihood methods and selected the best parameters for the model. We then conducted residual analysis using various techniques such as ACF plots, QQ plots, histograms, and the Shapiro-Wilk test to verify the accuracy and correctness of the model.

Overall, we have successfully demonstrated the effectiveness of the Box-Jenkins methodology and the ARIMA and GARCH models for time series analysis and forecasting of non-seasonal data. We have also shown the effectiveness of the SARIMA model for seasonal data. The models we have fitted to the datasets can be used to make future predictions and improve decision-making in various fields.

**REFERENCES**
1. Cryer, J. D., & Chan, K. S. (2008). Time series analysis: with applications in R (Vol. 2). NewYork: Springer38
2. Katesari, H. S., & Vajargah, B. F. (2015). Testing adverse selection using frank copula approachin Iran insurance markets. Mathematics and Computer Science,15(2), 154-158
3. Katesari, H. S., & Zarodi, S. (2016). Effects of coverage choice by predictive modeling onfrequency of accidents. Caspian Journal of Applied Sciences Research,5(3), 28-33
4. Safari-Katesari, H., Samadi, S. Y., & Zaroudi, S. (2020). Modelling count data via copulas.Statistics,54(6), 1329-1355
5. Shumway, R. H., Stoffer, D. S., & Stoffer, D. S. (2000). Time series analysis and its applications(Vol. 3). New York: springer
6. Safari-Katesari, H., & Zaroudi, S. (2020). Count copula regression model using generalized betadistribution of the second kind. Statistics,21, 1-12
7. Safari-Katesari, H., & Zaroudi, S. (2021). Analysing the impact of dependency on conditionalsurvival functions using copulas. Statistics in Transition New Series,22(1)
8. Safari Katesari, H., (2021) Bayesian dynamic factor analysis and copula-based models for mixeddata, PhD dissertation, Southern Illinois University Carbondale

**DATASET LINKS**
Non-Seasonal- https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#
Seasonal- https://in-the-sky.org/sunrise.php?startday=19&startmonth=4&startyear=2016&interval=7&tz=0
